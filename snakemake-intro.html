<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Introduction to Snakemake</title>
    <meta charset="utf-8" />
    <meta name="author" content="Dillon Barker" />
    <meta name="date" content="2021-10-14" />
    <script src="snakemake-intro_files/htmlwidgets/htmlwidgets.js"></script>
    <script src="snakemake-intro_files/viz/viz.js"></script>
    <link href="snakemake-intro_files/DiagrammeR-styles/styles.css" rel="stylesheet" />
    <script src="snakemake-intro_files/grViz-binding/grViz.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Introduction to Snakemake
### Dillon Barker
### 2021-10-14

---






## Lesson 1

1. Why Snakemake?
2. Introducing Workflows
3. Workflow Syntax
4. Running Snakemake
5. Assignment 1

Preparation for Assignment 1:
```bash
sbatch -c 1 --mem 4G --wrap \
"conda create -n smk-lesson-1 -c conda-forge -c bioconda prokka pirate snakemake"
```

---

## Why Snakemake?

.left-column[

**Automation**

Reproducibility

Others' Snakefiles

]

.right-column[
Front-loading your effort.

Modest investment at the beginning of a project yields a hands-off tool for
performing routine analyses.

]

---

## Why Snakemake?

.left-column[

Automation

**Reproducibility**

Others' Snakefiles

]

.right-column[
Guarantee that the same inputs will give the same outputs.

Altering any input will make Snakemake re-evalutate the outputs.

Built-in version tracking.
]

---

## Why Snakemake?

.left-column[

Automation

Reproducibility

**Others' Snakefiles**

]

.right-column[
Understand and modify the tools others have created for you.
]

---
## Baking with Graphs

![](figures/cookies-main.png)

---
## Thinking Backwards

- Snakemake figures out how to achieve the desired result:
  - starts at the final product
  - works backwards until it finds what it needs

- A collection of dependencies not a sequence of instructions

- You tell it how to convert each input to each output

---
## Thinking Backwards

![](figures/cookies-step-1.png)

---
## Thinking Backwards

![](figures/cookies-step-2.png)

---
## Thinking Backwards

![](figures/cookies-step-3.png)

---
## Thinking Backwards

![](figures/cookies-step-4.png)

---
## Thinking Backwards

![](figures/cookies-step-5.png)

---
## Thinking Backwards

![](figures/cookies-full.png)

---
## Rules for Baking

```python
rule all:
    input: "cookies"

rule bake_cookies:
    input: "pan/dough.blobs"
    output: "cookies"
    shell: "oven -i {input} -o {output} --temp 350 --time 15"

rule apportion_dough_blobs:
    input: "bowls/final.mix"
    output: "pan/dough.blobs"
    shell: "scoop -n 24 {input} &gt; {output}"
    
rule combine_bowls:
    input: wet="bowls/wet.mix", dry="bowls/dry.mix"
    output: "bowls/final.mix"
    shell: "mixer {input.wet} {input.dry} &gt; {output}"
```
---
## Rules for Baking

- The `all` rule is the final target, and written first

- Each rule specifies its `input` and `output`

- The `shell` command defines how the `input` becomes the `output`

- Snakemake matches up `input` and `output` for all the rules until it can generate `all`

---
## Baking → Bioinformatics
<div id="htmlwidget-7e47dc6632e4735e2741" style="width:100%;height:252px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-7e47dc6632e4735e2741">{"x":{"diagram":"\ndigraph {\n  rankdir=LR;\n  fastq[label=\"FASTQ\"];\n  fasta[label=\"Genome FASTA\"];\n  alleles[label=\"Core Alleles\", shape=\"MRecord\"];\n  calls[label=\"Calls Table\"];\n  \n  dummy[shape=point, width=0.01, height=0.01];\n  fastq -> fasta [label = \"SPAdes\"];\n\n  alleles -> dummy[dir = none, style=\"dashed\"];\n  fasta -> dummy[dir = none];\n  dummy -> calls[label = \"MLST\"];\n  \n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>

---
## Multiple Samples

<div id="htmlwidget-2a319665783cdda9044b" style="width:100%;height:252px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-2a319665783cdda9044b">{"x":{"diagram":"\ndigraph {\nrankdir=LR;\nalleles[label=\"alleles/aspA.fasta … uncA.fasta\", shape=MRecord];\ncalls[label=\"calls.tsv\"];\n\nfastqA[label=\"fastqs/genomeA.fastq\"];\nfastqB[label=\"fastqs/genomeB.fastq\"];\nfastqC[label=\"fastqs/genomeC.fastq\"];\n\nfastaA[label=\"assemblies/genomeA/contigs.fasta\"];\nfastaB[label=\"assemblies/genomeB/contigs.fasta\"];\nfastaC[label=\"assemblies/genomeC/contigs.fasta\"];\n\nmlstA[label=\"mlst_results/genomeA.tsv\"];\nmlstB[label=\"mlst_results/genomeB.tsv\"];\nmlstC[label=\"mlst_results/genomeC.tsv\"];\n\nfastqA -> fastaA [label=\"SPAdes\"];\nfastqB -> fastaB [label=\"SPAdes\"];\nfastqC -> fastaC [label=\"SPAdes\"];\n\ndummyA[shape=point, width=0.01, height=0.01];\ndummyB[shape=point, width=0.01, height=0.01];\ndummyC[shape=point, width=0.01, height=0.01];\ndummyD[shape=point, width=0.01, height=0.01];\n\nfastaA -> dummyA [dir=none];\nfastaB -> dummyB [dir=none];\nfastaC -> dummyC [dir=none];\nalleles -> {dummyA, dummyB, dummyC} [dir=none, style=\"dashed\"];\n\ndummyA -> mlstA [label=\"MLST\"];\ndummyB -> mlstB [label=\"MLST\"];\ndummyC -> mlstC [label=\"MLST\"];\n\n{mlstA, mlstB, mlstC} -> dummyD [dir=none];\ndummyD -> calls [label=\"combine\"];\n}\n","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
---
## Multiple Samples

- Recall that rules are only executed if their inputs update or outputs are missing

- Lets you run jobs without worrying you'll waste effort

### MLST Example from Above

1. If you have 1000 genomes and run the above MLST rule, it will calculate 1000 calls, and build the calls table
2. If you add 1 more genome, and rerun snakemake, only a single MLST will run, and the calls table is rebuilt

---
## Wildcards

- We can match every file with particular naming pattern with wildcards

- In a rule, wrap a variable name with curly braces
    - _e.g._ `{sample}`

- Rule will be applied in parallel to each file matching the rule

- In `shell` block, you can access these when preceded by `wildcards`
    - _e.g._ `{wildcards.sample}`

---
## Expanding patterns

- The `expand()` function can be useful for taking a pattern and using it to get many files matching that pattern

```python
# get sample names from starting fastas
# genomes/foo.fasta, genome/bar.fasta, genome/baz.fasta
from pathlib import Path
samples = [p.stem for p in Path("genomes").glob("*.fasta")]
# samples = ["foo", "bar", "baz"]

rule all:
    input: "aggregated_results.txt"

rule process_genomes:
    input: "genomes/{sample}.fasta"
    output: "results/{sample}.txt"
    shell: "frobnicate {input} &gt; {output}"

rule takes_many_files:
    input: expand("results/{sample}.txt", sample=samples)
    output: "aggregated_results.txt"
```
---
## Rules for Multiple Samples

```python
from pathlib import Path
sample_names = [fq.stem for fq in Path("fastqs").glob("*")]

rule all:
    input: "calls.tsv"
    
rule assemble:
    input:
        fwd="fastqs/{sample}/{sample}_1.fastq", rev="fastqs/{sample}/{sample}_2.fastq"
    output: "assemblies/{sample}/contigs.fasta"
    shell: "spades -1 {input.fwd} -2 {input.rev} -o assemblies/{wildcards.sample}"

rule get_sequence_types:
    input: "assemblies/{sample}/contigs.fasta"
    output: "mlst_results/{sample}.tsv"
    shell: "mlst --scheme campylobacter {input} &gt; {output}"
    
rule combine_mlst_results:
    input: expand("mlst_results/{sample}.tsv", sample=sample_names)
    output: "calls.tsv"
    shell: "cat {input} &gt; {output}"
```
---
## Threads

- Many (but not all!) bioinformatics tools use multiple CPU threads
- `threads` directive defaults to `1`
    - Accessible in the `shell` block, similar to `input` and `output`
      - `{threads}`

```python
rule annotate_genome:
    input: "genomes/{sample}.fasta"
    output: "annotations/{sample}/{sample}.gff"
    threads: 8
    shell: "prokka --cpus {threads} -o annotations/{wildcards.sample} {input}"
```
---
## Caveats and Assumptions

### Directory Structure

- Snakefiles themselves can live anywhere
    - I keep mine in `~/snakefiles/`

- Workflows tightly coupled to any directory structure described within
- Will implicitly create any directories it needs
    - No need for `mkdir`


---
## Directory Structure

This rule…

```python
rule annotate_genome:
    input: "genomes/{sample}.fasta"
    output: "annotations/{sample}/{sample}.gff"
    threads: 8
    shell: "prokka --cpus {threads} -o annotations/{wildcards.sample} {input}"
```
_requires_ this structure:

```
analysis/
├── annotations/
│   ├── isolateA.fasta
│   ├── isolateB.fasta
│   └── isolateC.fasta
└── genomes/
    ├── isolateA.fasta
    ├── isolateB.fasta
    └── isolateC.fasta
```

---
## Caveats and Assumptions
### Independent Jobs

- Failure of any job will abort all other jobs
    - Override with `--keep-going`
    - Dependent jobs will still await all inputs
    - _e.g._ if stiring the dry cookie mixture fails, the wet mixture still gets made, but nothing goes in the oven
---

## Running Snakemake (Basic)

The **basic invocation** of Snakemake:
```bash
snakemake --jobs &lt;number of parallel jobs&gt; -s &lt;path to your Snakefile&gt; -d &lt;work directory&gt;
```

Example populated with real values:
```bash
snakemake --jobs 5 -s ~/snakefiles/assemble.smk -d ~/Projects/cj_population_study
```
---

## Running Snakemake on Waffles

- Snakemake can be run on HPCs like **Waffles**
  - _Must_ be combined with Slurm
    - _Don't run it on the head node!_

- Two parts:
  1. Tell Snakemake how to submit jobs with `--cluster`
  2. Submit Snakemake itself as a Slurm job

---
## Running Snakemake on Waffles

The `--cluster` argument:

- Create a template command to pass to **Slurm**
- May access Snakemake special variables like `{threads}`
    - **More on this later**
    
`--cluster 'sbatch -c {threads} --mem 12G --partition NMLResearch '`

---
## Running Snakemake on Waffles

Submitting the Snakemake job to Slurm:

`sbatch -c 1 --mem 4G --wrap "snakemake --jobs 5 -s ~/snakefiles/assemble.smk -d ~/Projects/cj_population_study --cluster 'sbatch -c {threads} --mem 12G --partition NMLResearch '"`
---
## Assignment 1

Write a Snakemake workflow that does the following:

1. Run Prokka on each genome
2. Symlink GFF annotations into `gffs/`
3. Build a pangenome with PIRATE

`conda activate smk-lesson-1`
---
class: inverse, center, middle

# Lesson 2

---
## Lesson 2

1. Assignment 1 Answers
2. Conda Integration
3. Params and Threads
4. Mixing in Python
5. Assignment 2

---
## Assignment 1

---
## Conda Integration

- Snakemake can manage `conda` directly
- No need to manually build or activate conda environments

### Conda directive
```python
rule annotate_genome:
    input: "genomes/{sample}.fasta"
    output: "annotations/{sample}/{sample}.gff"
    conda: "envs/prokka.yaml"
    shell: "prokka --cpus {threads} -o annotations/{wildcards.sample} {input}"
```
---

## Conda YAML files

- Placed **relative to the Snakefile**, _not_ the project directory

```python
# annotate.smk
rule annotate_genome:
    input: "genomes/{sample}.fasta"
    output: "annotations/{sample}/{sample}.gff"
    conda: "envs/prokka.yaml"
    shell: "prokka --cpus {threads} -o annotations/{wildcards.sample} {input}"
```

The above will look for the following directory structure:

```sh
snakefiles/
├── annotate.smk
└── envs
    └── prokka.yaml
```
---
## Conda YAML files

This YAML file …
```yaml
name: prokka
channels:
    - conda-forge
    - bioconda
    - defaults
dependencies:
    - prokka
```
… is equivalent to this conda command:
```sh
conda create -n prokka -c conda-forge -c bioconda -c defaults prokka
```
---
## Using Conda Directives with Snakemake

- Must explicitly tell Snakemake to use Conda

```sh
snakemake --use-conda &lt;…&gt;
```

- Automatic installation and activation

---
## Config
Configuration is possible through `config`
- Python `dict` available within the Snakefile

- Available through two methods
    - `--config` passes arguments directly via command line
    - `--configfile` points to a YAML file that provides values

`--config "key=value"` is equivalent to `--configfile config.yaml` where…

```yaml
# config.yaml
key: "value"
```

---

### Configuration via:
.pull-left[
`--config` flag:
- ↓ effort
- ↑ flexible
- ↓ reproducible
]
.pull-right[
YAML file:
- ↑ effort
- ↓ flexible
- ↑ reproducible
]
---
## Params

- Non-file parameters may be provided in the `params` directive
---

## Abusing Params to Fine-tune Resources

```sh
snakemake &lt;…&gt; --cluster 'sbatch -c {threads} --mem {params.mem} --time {params.time} '
```

```python
rule annotate_genome:
    input: "genomes/{sample}.fasta"
    output: "annotations/{sample}/{sample}.gff"
    threads: 8
    params:
        time="45:00",
        mem="16G"
    shell: "prokka --cpus {threads} -o annotations/{wildcards.sample} {input}"

rule symlink_gff:
    input: "annotations/{sample}/{sample}.gff"
    output: "gffs/{sample}.gff"
    threads: 1
    params:
        time="01:00",
        mem="100M"
    shell: "ln -sr {input} {output}"
```


---
## Config vs Params

- Params are fairly "fixed"
    - Used primarily to simplify `shell` block

- Config for run-specific information
    - _ e.g._ providing a particular host database to `kat` or training file to `chewBBACA`

---
## Mixing in Python

- Python may be mixed in arbitrarily into Snakemake
    - _i.e._ All Python is valid Snakemake

- Two main ways of using Python in Snakemake
    - `run` blocks
    - Python used directly in the Snakemake file


.footnote[Python → Snakemake, get it‽]

---
## Run blocks

- `run` blocks can be used in place of `shell` blocks

- Write Python inside the `run` block, rather than Bash in a `shell` block

- May access snakemake values like `input` and `output`

```python
rule transpose_table:
    input: "data/results_table.csv"
    output: "data/results_table_transposed.csv"
    run:
        import pandas as pd
        original = pd.read_csv(input[0], header=0)
        transposed = original.transpose()
        transposed.to_csv(output[0], header=False)
```

---

## Directly Using Python in Snakemake

- You can directly use Python in Snakemake

- Particularly useful for handling cases where a rule generates variable output
    - _e.g._ The number of gene FASTAs generated by a pangenome analysis

- Can provide a Python function to `input` instead of a file pattern

---

- `select_high_quality_genomes` takes a list of FASTAs, then symlinks
high-quality ones into `./good_genomes/` and writes a report called
`quality_report.txt`

- We don't know in advance which genomes will pass QC, so we need an input
function

```python

rule quality_filter_genomes:
    input: expand("genomes/{sample}.fasta", sample=samples)
    output: "quality_report.txt"
    shell: "select_high_quality_genomes {input} &gt; {output}"

# input functions need to take parameter `wildcards`
def collect_good_genome_sample_names(wildcards):
    good_genomes = Path("good_genomes/").glob("*.fasta")
    return list(good_genomes)

# use the report as a dummy input to make sure quality_filter_genomes executes
rule run_abricate:
    input: report="quality_report.txt", fastas=collect_good_genome_sample_names
    output: "amr_results.tsv"
    shell: "abricate {input.fastas} &gt; {output}"
```
---
## Assignment 2

- Build upon Assignment 1

1. Create conda YAMLs for `prokka` and `pirate`

2. Give appropriate resources to each rule with `params`

3. Write a rule with a `run` block that reads `PIRATE.gene_families.tsv`, finds loci present in 100% of genomes, and writes their names to a text file
    - columns of interest: `gene_family` &amp; `number_genomes`

4. A rule that:
    - Uses an input function reads selected genes from the text file in **Part 3**
    - Symlinks these into a directory called `loci`
        - Either `shell` or `run` at your preference

---

## Assignment 2 Hints

### `pandas` for easily reading tabular files
```python
import pandas as pd
data_table = pd.read_csv(input[0], sep = "\t")
# select rows from columnA where columnC is greater than 42
selected_rows = data_table["columnC"] &gt; 42
selected_columnA = data_table["columnA"].loc[selected_rows]
```

### Creating symlinks from a list of file basenames
```python
# list_of_names = ["larry", "moe", "curly"]
import os
for name in list_of_names:
    src = f"originals/{name}.txt"
    dst = f"filtered/{name}.txt"
    os.symlink(src, dst)
```

---

## Assignment 2 Hints

### Reading a text file into a list with Python

- Consider combining functions like this with `expand()`
    - `expand("path/to/{sample}.txt", sample=read_list_to_list())`

```python
def read_lines_to_list(path: str):
    lines = []
    with open(path, "r") as f:
        for line in f:
            trimmed_line = line.strip()
            lines.append(trimmed_line)
    return lines
```

---
### Reading a text file, but using at as an input function

```python
def aggregate_files(path: str):
    lines = []
    with open(path, "r") as f:
        for line in f:
            trimmed_line = line.strip()
            lines.append(trimmed_line)
    lines_with_paths = [f"path/to/{sample}.txt" for sample in lines]
    return lines_with_paths
```

```python
rule do_something:
    input: aggregate_files
    output: "somefile.txt"
    shell: "my_program {input} -o {output}"
```
---
class: inverse, center, middle

# Lesson 3

---

## Lesson 3

1. Assignment 2 Answer
2. Fixing when things go wrong
3. Priorities
4. Script files (Python, R, and Julia)
5. Visualizing Workflows
6. Clinic

---

## Assignment 2

---

## When Things Go Wrong

- Snakemake locks its working directory when running
    - Prevents other snakemake instances from running in the same place

- Snakemake removes the lock when it completes (success _or_ failure)

- Lockfile may not be removed when if snakemake crashes or is killed by slurm
    - `scancel --user your_username`


```sh
Unable to lock working directory.
```

---

## Unlocking a Stale Lock

#### The Correct Way: `--unlock`

```bash
sbatch -c 1 --mem 2G --wrap "snakemake --unlock -s path/to/your/workflow.smk -j 1"
```

#### ☠☠☠ Nuclear Option ☠☠☠

```bash
rm -r ./.snakemake
```

---
## Priorities

.pull-left[
- Rule priorities may be set

- These **are not** the same as slurm partitions

- Only determine the priority of execution within the workflow

- Rules default to priority `0`

- Bigger numbers are higher priority
]

.pull-right[
```python
rule my_example:
  input: ...
  output: ...
  priority: 50
  shell: ...
```
]

---
## Script Files

- Can be used like a `run` block, but stored in another file
    - Path is specified relative to the workflow

- Available languages:
    - Python
    - R
    - Julia
    
- Snakemake will use special variables in the script
    - These scripts won't be general purpose!
    - Tied to snakemake

---
## Script Files

```python
# workflow.smk
rule scriptfile_example:
    input:
        "path/to/inputfile",
        "path/to/other/inputfile"
    output:
        "path/to/outputfile",
        "path/to/another/outputfile"
    script:
        "scripts/script.py"
```

```python
# scripts/script.py
def do_something(data_path, out_path, threads, myparam):
    # python code here

do_something(snakemake.input[0], snakemake.output[0], 
             snakemake.threads, snakemake.config["myparam"])
```

---
## Visualizing Workflows


```bash
# Shows just the abstract graph of rules
snakemake -s your/workflow.smk --rulegraph | dot -Tpng &gt; workflow.png
# OR
# Show every sample's journey through the workflow
snakemake -s your/workflow.smk --dag | dot -Tpng &gt; workflow.png
```


<div id="htmlwidget-750586d75dc34b9b0dab" style="width:100%;height:252px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-750586d75dc34b9b0dab">{"x":{"diagram":"digraph snakemake_dag {\n    graph[bgcolor=white, margin=0, rankdir=LR];\n    node[shape=box, style=rounded, fontname=sans, fontsize=10, penwidth=2];\n    edge[penwidth=2, color=grey];\n\t0[label = \"all\", color = \"0.51 0.6 0.85\", style=\"rounded\"];\n\t1[label = \"calculate_ntb\", color = \"0.09 0.6 0.85\", style=\"rounded\"];\n\t2[label = \"run_feht\", color = \"0.24 0.6 0.85\", style=\"rounded\"];\n\t3[label = \"find_maximum_negative_threshold\", color = \"0.62 0.6 0.85\", style=\"rounded\"];\n\t4[label = \"expand_cohorts\", color = \"0.36 0.6 0.85\", style=\"rounded\"];\n\t5[label = \"cluster_grapetree\", color = \"0.49 0.6 0.85\", style=\"rounded\"];\n\t6[label = \"calculate_newick_tree\", color = \"0.00 0.6 0.85\", style=\"rounded\"];\n\t7[label = \"format_grapetree_calls\", color = \"0.60 0.6 0.85\", style=\"rounded\"];\n\t8[label = \"calculate_cohorts\", color = \"0.11 0.6 0.85\", style=\"rounded\"];\n\t9[label = \"binarize_markers\", color = \"0.18 0.6 0.85\", style=\"rounded\"];\n\t10[label = \"get_PIRATE_to_Rtab\", color = \"0.64 0.6 0.85\", style=\"rounded\"];\n\t11[label = \"pirate_pangenome\", color = \"0.29 0.6 0.85\", style=\"rounded\"];\n\t12[label = \"get_positive_primers\", color = \"0.33 0.6 0.85\", style=\"rounded\"];\n\t13[label = \"concatenate_blast_results\", color = \"0.40 0.6 0.85\", style=\"rounded\"];\n\t14[label = \"blast_top_pairs_against_genomes\", color = \"0.27 0.6 0.85\", style=\"rounded\"];\n\t15[label = \"fastulate_top_pairs\", color = \"0.42 0.6 0.85\", style=\"rounded\"];\n\t16[label = \"extract_top_pairs\", color = \"0.22 0.6 0.85\", style=\"rounded\"];\n\t17[label = \"select_top_primers\", color = \"0.53 0.6 0.85\", style=\"rounded\"];\n\t18[label = \"format_primer_table\", color = \"0.47 0.6 0.85\", style=\"rounded\"];\n\t19[label = \"generate_primer\", color = \"0.16 0.6 0.85\", style=\"rounded\"];\n\t20[label = \"generate_primer_configs\", color = \"0.58 0.6 0.85\", style=\"rounded\"];\n\t21[label = \"generate_consensus_sequence\", color = \"0.38 0.6 0.85\", style=\"rounded\"];\n\t22[label = \"summarize_balanaced\", color = \"0.04 0.6 0.85\", style=\"rounded\"];\n\t23[label = \"symlink_balanced_ntb\", color = \"0.07 0.6 0.85\", style=\"rounded\"];\n\t24[label = \"calculate_ntb_balanced\", color = \"0.44 0.6 0.85\", style=\"rounded\"];\n\t25[label = \"run_feht_balanced\", color = \"0.13 0.6 0.85\", style=\"rounded\"];\n\t26[label = \"transpose_balanced\", color = \"0.56 0.6 0.85\", style=\"rounded\"];\n\t27[label = \"create_balanced_cohorts\", color = \"0.02 0.6 0.85\", style=\"rounded\"];\n\t28[label = \"transpose_binary_markers\", color = \"0.20 0.6 0.85\", style=\"rounded\"];\n\t29[label = \"generate_primer_pair_calls\", color = \"0.31 0.6 0.85\", style=\"rounded\"];\n\t29 -> 0\n\t12 -> 0\n\t1 -> 0\n\t2 -> 1\n\t3 -> 2\n\t4 -> 2\n\t9 -> 2\n\t4 -> 3\n\t5 -> 4\n\t8 -> 4\n\t6 -> 5\n\t7 -> 6\n\t5 -> 8\n\t11 -> 9\n\t10 -> 9\n\t13 -> 12\n\t14 -> 13\n\t15 -> 14\n\t16 -> 15\n\t17 -> 16\n\t22 -> 17\n\t18 -> 17\n\t19 -> 18\n\t20 -> 19\n\t21 -> 20\n\t11 -> 21\n\t23 -> 22\n\t24 -> 23\n\t25 -> 24\n\t27 -> 25\n\t3 -> 25\n\t26 -> 25\n\t27 -> 26\n\t3 -> 27\n\t4 -> 27\n\t28 -> 27\n\t9 -> 28\n\t12 -> 29\n}            ","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>

---
class: center, middle

# Clinic
## Please feel free to ask any questions!
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"slideNumberFormat": "%current%",
"highlightStyle": "github",
"highlightLines": true,
"ratio": "16:9",
"countIncrementalSlides": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
